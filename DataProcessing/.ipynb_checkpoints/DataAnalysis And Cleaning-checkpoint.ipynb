{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path = path.split('CIS550_Group_Project')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = pd.read_csv(path + 'data/listings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pd.unique(l1['neighbourhood']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)Generate Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summaryStats = l1.describe()\n",
    "#summaryStats.to_csv('data/listing_summary_stats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)Subset Useful Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_columns = ['id', 'listing_url', 'name', 'description',\n",
    "       'neighborhood_overview', 'picture_url', 'host_id', 'host_url',\n",
    "       'host_name', 'host_since', 'host_about',\n",
    "       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
    "       'host_is_superhost', 'host_picture_url',\n",
    "       'host_listings_count',\n",
    "       'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude',\n",
    "       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n",
    "       'bathrooms_text', 'bedrooms', 'beds', 'price',\n",
    "       'minimum_nights', 'maximum_nights', \n",
    "       'availability_365', 'number_of_reviews',\n",
    "       'review_scores_rating', 'review_scores_accuracy',\n",
    "       'review_scores_cleanliness', 'review_scores_checkin',\n",
    "       'review_scores_communication', 'review_scores_location',\n",
    "       'review_scores_value', 'instant_bookable']\n",
    "l2 = l1[useful_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)Convert bathroom_text column to bathrooms column(numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l2['bathrooms'] = l2['bathrooms_text'].astype(str).apply(lambda x: x.split(' ')[0] if len(x.split(' ')) > 0 else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-204-11ae1bb7fdc9>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  l2['bathrooms'] = l2['bathrooms_text'].apply(extract_bathroom)\n"
     ]
    }
   ],
   "source": [
    "def extract_bathroom(x):\n",
    "    blist = str(x).split(' ')\n",
    "    if len(blist) > 0:\n",
    "        try:\n",
    "            float(blist[0])\n",
    "            return float(blist[0])\n",
    "        except ValueError:\n",
    "            if 'half' in str(x).lower():\n",
    "                return 0.5\n",
    "    return None\n",
    "\n",
    "l2['bathrooms'] = l2['bathrooms_text'].apply(extract_bathroom)\n",
    "l2 = l2.drop(columns=['bathrooms_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Convert Price column to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2['price'] = l2['price'].str.replace('$','').str.replace(\",\",'').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6)rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2.rename(columns = {'neighbourhood_cleansed':'neighbourhood', \n",
    "                     'neighbourhood_group_cleansed':'neighbourhood_group',\n",
    "                     'id':'listing_id'}, \n",
    "          inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert host_since to MySql default date format YYYY-mm-dd\n",
    "# l2['host_since'] = pd.to_datetime(l2['host_since'], infer_datetime_format=True).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7)Convert host_response_rate to numeric, remove %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2['host_response_rate'] = l2['host_response_rate'].str.replace('%','').astype(float)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (8)Convert host_acceptance_rate to numeric, remove %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2['host_acceptance_rate'] = l2['host_acceptance_rate'].str.replace('%','').astype(float)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (9) Demopose to take host information into host table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36724, 10)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_columns = ['host_id', 'host_url',\n",
    "       'host_name', 'host_since',\n",
    "       'host_response_time', 'host_response_rate', 'host_acceptance_rate',\n",
    "       'host_is_superhost', 'host_picture_url',\n",
    "       'host_listings_count']\n",
    "host = l2[host_columns]\n",
    "host.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25690,)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 25690 unique host_id\n",
    "host['host_id'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-212-b9474bdaa677>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  host.drop_duplicates(inplace=True, keep=\"first\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25690, 10)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## after removing duplicates, there are 25690 records for host table\n",
    "host.drop_duplicates(inplace=True, keep=\"first\") \n",
    "host.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "host.to_csv(path + 'data/host_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (10) save listing (remove host columns) into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_removehost_columns = ['listing_id', 'listing_url', 'host_id','name', 'description', \n",
    "       'neighborhood_overview', 'picture_url', \n",
    "       'neighbourhood', 'neighbourhood_group', 'latitude',\n",
    "       'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',\n",
    "       'bathrooms', 'bedrooms', 'beds', 'price',\n",
    "       'minimum_nights', 'maximum_nights', \n",
    "       'availability_365', 'number_of_reviews',\n",
    "       'review_scores_rating', 'review_scores_accuracy',\n",
    "       'review_scores_cleanliness', 'review_scores_checkin',\n",
    "       'review_scores_communication', 'review_scores_location',\n",
    "       'review_scores_value', 'instant_bookable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = l2[listing_removehost_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3.to_csv(path + 'data/listing_removehost_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = pd.read_csv(path + 'data/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_non_digit(x):\n",
    "    match = re.findall(r\"\\D\",x)\n",
    "    if len(match) > 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "r1[\"listing_id\"] = r1[\"listing_id\"].astype(str).apply(scan_non_digit)\n",
    "r1[\"id\"] = r1[\"id\"].astype(int).astype(str).apply(scan_non_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [listing_id, id, date, reviewer_id, comments]\n",
       "Index: []"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check problematic id columns\n",
    "check = r1[(r1['listing_id']== \"\") | (r1['id']== \"\") ]\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = r1.drop(columns=['comments'])\n",
    "r1.rename(columns = {'id': 'review_id'}, \n",
    "          inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r1.drop_duplicates(subset = ['review_id'], keep='first')\n",
    "#r2 = r2.sample(n = 75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2.to_csv(path + 'data/review_cleaned_sample.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_geojson(file_path):\n",
    "    \n",
    "    with open(file_path) as f:\n",
    "        gj = geojson.load(f)\n",
    "    \n",
    "        results = []\n",
    "    \n",
    "    for record in gj[\"features\"]:\n",
    "        coord = np.array(record['geometry']['coordinates'][0][0])\n",
    "        min_coord = list(np.amin(coord,axis=0))\n",
    "        max_coord = list(np.amax(coord,axis=0))\n",
    "        results.append({\n",
    "            \"neighbourhood\" : record[\"properties\"][\"neighbourhood\"]\n",
    "            ,\"neighbourhood_group\": record[\"properties\"][\"neighbourhood_group\"]\n",
    "            ,\"minx\": min_coord[0]\n",
    "            ,\"maxx\": max_coord[0]\n",
    "            ,\"miny\": min_coord[1]\n",
    "            ,\"maxy\": max_coord[1]\n",
    "            ,\"centerx\": (min_coord[0] + max_coord[0])/2\n",
    "            ,\"centery\": (min_coord[1] + max_coord[1])/2\n",
    "           })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge target data with neighborhood data by fuzzy join on neightborhood latitude & longtitude range\n",
    "def match_region_by_latlong(target_df, nbr_df):\n",
    "    \n",
    "    lat = target_df['latitude'].values\n",
    "    long = target_df['longitude'].values\n",
    "    \n",
    "    nbr_latlow = nbr_df['miny'].values\n",
    "    nbr_lathigh = nbr_df['maxy'].values\n",
    "    nbr_longlow = nbr_df['minx'].values\n",
    "    nbr_longhigh = nbr_df['maxx'].values\n",
    "    \n",
    "    i, j = np.where((lat[:, None] >= nbr_latlow) & (lat[:, None] <= nbr_lathigh) &\n",
    "                 (lat[:, None] >= nbr_longlow) & (long[:, None] <= nbr_longhigh))\n",
    "    \n",
    "    merge_df = pd.DataFrame(\n",
    "                np.column_stack([target_df.values[i], nbr_df.values[j]]),\n",
    "                columns = target_df.columns.append(nbr_df.columns)\n",
    "                )\n",
    "    \n",
    "    merge_df['dist_to_center'] = (merge_df['longitude'] - merge_df['centerx'])**2 + (merge_df['latitude'] - merge_df['centerx'])**2\n",
    "    \n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr = parse_geojson(path + 'data/neighbourhoods.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### double check all listing neighborhood included in this neighborhood dataset\n",
    "for item in list(pd.unique(l2[\"neighbourhood\"])):\n",
    "    if item not in list(nbr[\"neighbourhood\"]):\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign NeighborHood to Museum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 9)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = pd.read_csv(path + 'data/MUSEUM_New_York_cleaned.csv')\n",
    "m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1['longitude'] = -m1['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1444, 18)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = match_region_by_latlong(m1, nbr)\n",
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.107692307692307"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## neighborhoods per Museum\n",
    "m2.shape[0]/m1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2['dist_to_center'] = m2['dist_to_center'].astype('float')\n",
    "m2[\"distance_rank\"] = m2.groupby(\"id\")[\"dist_to_center\"].rank(method = \"first\", ascending=True)\n",
    "m2 = m2[m2[\"distance_rank\"] <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2.to_csv(path + 'data/MUSEUM_with_nbr.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Neighborhood to ArtGallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(917, 9)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = pd.read_csv(path + 'data/ART_GALLERY_New_York_cleaned.csv')\n",
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1['longitude'] = -a1['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11721, 18)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2 = match_region_by_latlong(a1, nbr)\n",
    "a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.781897491821155"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#neighborhood per ArtGallery\n",
    "a2.shape[0]/a1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4527, 19)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2['dist_to_center'] = a2['dist_to_center'].astype('float')\n",
    "a2[\"distance_rank\"] = a2.groupby(\"id\")[\"dist_to_center\"].rank(method = \"first\", ascending=True)\n",
    "a2 = a2[a2[\"distance_rank\"] <= 5]\n",
    "a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2.to_csv(path + 'data/ART_GALLERY_with_nbr.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Neighborhood to Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3706, 4)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = pd.read_csv(path + 'data/Park_New_York_cleaned.csv')\n",
    "p1['longitude'] = -p1['longitude']\n",
    "p1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30014, 13)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = match_region_by_latlong(p1, nbr)\n",
    "p2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.09875876956287"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#neighborhoods per Park\n",
    "p2.shape[0]/p1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4319, 14)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2['dist_to_center'] = p2['dist_to_center'].astype('float')\n",
    "p2[\"distance_rank\"] = p2.groupby(\"id\")[\"dist_to_center\"].rank(method = \"first\", ascending=True)\n",
    "p2 = p2[p2[\"distance_rank\"] <= 5]\n",
    "p2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.to_csv(path + 'data/PARK_with_nbr.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Neighborhood to Crime Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73437, 7)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1 = pd.read_csv(path + 'data/NYPD_Arrest_Data__Year_to_Date_Clean.csv')\n",
    "c1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596800, 16)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2 = match_region_by_latlong(c1, n1)\n",
    "c2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.126693628552365"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###neighborhoods per Crime incident\n",
    "c2.shape[0]/c1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73395, 17)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2['dist_to_center'] = c2['dist_to_center'].astype('float')\n",
    "c2[\"distance_rank\"] = c2.groupby(\"arrest_key\")[\"dist_to_center\"].rank(method = \"first\", ascending=True)\n",
    "c2 = c2[c2[\"distance_rank\"] <= 1]\n",
    "c2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2.to_csv(path + 'data/Crime_with_nbr.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
